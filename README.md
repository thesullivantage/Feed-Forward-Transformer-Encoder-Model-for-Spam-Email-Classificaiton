# Feed-Forward Transformer Encoder Model for Spam Email Classification

- A deep, feed-forward classification model built using text vectorization, custom pre-processing, and a transformer encoder network for spam email classification. 

- Designed for a client. Future work will entail refactoring the model in PyTorch and the construction of an MLOps pipeline on AWS Sagemaker for training, evaluation, and serving of inferences.

- Exclude the dataset here. Any labelled spam email dataset with a structure of ['email_text', 'label'] (containing a reasonable distribution of word counts per 'email_text' example) should be usable with the model. 
